{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales Artificiales - Trabajo Práctico 1\n",
    "\n",
    "### Guillermina Cabrol, Magalí Giansiracusa, Sofía Goldberg\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En este trabajo implementaremos modelos de redes neuronales artificiales para aprendizaje supervisado, para dos problemas distintos: **Diagnóstico de cáncer de mamas** y **Eficiencia energética**. Se hará un análisis de los datos obtenidos y los modelos construidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt, cm\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una función para separar los datos en entrenamiento (`train`), validación (`val`) y testeo (`test`). Como sus nombres indican, usaremos los datos de entrenamiento para entrenar la red, los de validación para comprobar qué tan bien predice la red para datos no utilizados en el entrenamiento y poder ajustar parámetros para mejorar la performance, y por último, usaremos el dataset de testeo para calificar el modelo final y estimar su desempeño en la realidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, floor\n",
    "import random\n",
    "\n",
    "def split(\n",
    "        X: np.ndarray,\n",
    "        Z: np.ndarray,\n",
    "        test_size: float,\n",
    "        train_size: int,\n",
    "        val_size: int,\n",
    "    ) -> tuple:\n",
    "\n",
    "    \"\"\"Separa el conjunto de datos en conjuntos de train, validation y test al azar.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: datos de entrada.\n",
    "    \n",
    "    Z: datos objetivo.\n",
    "\n",
    "    test_size: proporción del dataset a incluir en test.\n",
    "    \n",
    "    train_size: proporción del dataset a incluir en train.\n",
    "\n",
    "    val_size: proporción del dataset a incluir en validation.\n",
    "\n",
    "    random_state: sirve para que los resultados sean reproducibles.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    split: lista que contiene el conjunto de test y el de train.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(X)\n",
    "\n",
    "    n_test = ceil(test_size * n)\n",
    "    n_train = floor(train_size * n)\n",
    "    n_val = ceil(val_size * n)\n",
    "\n",
    "    n_train, n_test, n_val = int(n_train), int(n_test), int(n_val)\n",
    "\n",
    "\n",
    "    X_train = X[:n_train]\n",
    "    X_test = X[(n_train + 1):(n_train + n_test + 1)]\n",
    "    X_val = X[(n_train + n_test):(n_train + n_test + n_val)]\n",
    "\n",
    "    Z_train = Z[:n_train]\n",
    "    Z_test = Z[(n_train + 1):(n_train + n_test + 1)]\n",
    "    Z_val = Z[(n_train + n_test):(n_train + n_test + n_val)]\n",
    "\n",
    "    return X_train, Z_train, X_val, Z_val, X_test, Z_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnóstico de cáncer de mamas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, cargamos los datos, y los separamos en X (datos de entrada) y Z (datos objetivo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000000e+00, 1.829800e+01, 1.159600e+01, 1.544920e+02,\n",
       "       1.370281e+03, 9.330000e-01, 1.291000e+00, 5.229000e+00,\n",
       "       6.866000e+00, 7.600000e-01, 2.164000e+00])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "r = requests.get('https://git.exactas.uba.ar/redes-neuronales/clases/-/raw/master/practicas/datos/tp1_ej1_training.csv')\n",
    "data = np.loadtxt(r.iter_lines(), delimiter=',')\n",
    "\n",
    "\n",
    "\n",
    "data = np.random.RandomState(seed=42).permutation(data)\n",
    "\n",
    "X = data[1,:]\n",
    "\n",
    "Z = data[:,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos:\n",
    "\n",
    "- 80% para entrenamiento.\n",
    "- 15% para validación.\n",
    "- 5% para testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Z_train, X_val, Z_val, X_test, Z_test = split(X, Z, 0.05, 0.8, 0.15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de datos\n",
    "\n",
    "Vamos a realizar un análisis de los datos para ver su distribución y cuán correlacionados están, para así decidir si es necesario realizar alguna modificación.\n",
    "\n",
    "Para esto, pasaremos los datos a formato *DataFrame* usando la librería `Pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0       1       2        3         4      5      6      7      8    \n",
      "0    0.0  20.284  13.181  158.656  1179.240  1.205  1.878  4.898  5.932  \\\n",
      "1    0.0  18.298  11.596  154.492  1370.281  0.933  1.291  5.229  6.866   \n",
      "2    1.0  23.810  26.490   48.872   740.533  1.970  2.042  0.427  0.434   \n",
      "3    0.0  25.137  15.136   94.484   694.296  1.594  0.683  1.846  2.414   \n",
      "4    1.0  25.586  12.223  147.360  1598.108  0.816  1.121  3.131  2.793   \n",
      "..   ...     ...     ...      ...       ...    ...    ...    ...    ...   \n",
      "405  1.0  22.379  13.553  103.688  1057.360  1.311  1.613  2.654  3.739   \n",
      "406  0.0  18.123  25.380   78.628   676.326  1.907  2.363  3.008  4.713   \n",
      "407  1.0  15.199  26.687  128.923   792.511  2.002  1.664  4.849  5.776   \n",
      "408  1.0  14.836  27.011  117.617   769.889  2.003  2.413  4.611  5.819   \n",
      "409  1.0  23.188  13.113  114.707  1050.123  1.288  1.679  3.199  4.697   \n",
      "\n",
      "        9      10  \n",
      "0    1.029  2.019  \n",
      "1    0.760  2.164  \n",
      "2    0.651  0.267  \n",
      "3    0.784  0.830  \n",
      "4    0.814  1.933  \n",
      "..     ...    ...  \n",
      "405  0.362  1.409  \n",
      "406  1.100  0.469  \n",
      "407  1.200  1.637  \n",
      "408  1.060  1.508  \n",
      "409  1.089  0.899  \n",
      "\n",
      "[410 rows x 11 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.986076</td>\n",
       "      <td>-0.555247</td>\n",
       "      <td>-0.688773</td>\n",
       "      <td>1.015114</td>\n",
       "      <td>-0.376337</td>\n",
       "      <td>-0.965236</td>\n",
       "      <td>0.162332</td>\n",
       "      <td>0.444110</td>\n",
       "      <td>0.700759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.266410</td>\n",
       "      <td>-0.004133</td>\n",
       "      <td>-1.237597</td>\n",
       "      <td>1.015114</td>\n",
       "      <td>-0.376337</td>\n",
       "      <td>0.162596</td>\n",
       "      <td>-0.468085</td>\n",
       "      <td>1.127716</td>\n",
       "      <td>0.872743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.536933</td>\n",
       "      <td>1.098093</td>\n",
       "      <td>0.957697</td>\n",
       "      <td>-0.985111</td>\n",
       "      <td>-1.294232</td>\n",
       "      <td>0.162596</td>\n",
       "      <td>0.162332</td>\n",
       "      <td>-0.818550</td>\n",
       "      <td>-1.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.415596</td>\n",
       "      <td>-1.106360</td>\n",
       "      <td>0.957697</td>\n",
       "      <td>-0.985111</td>\n",
       "      <td>0.541558</td>\n",
       "      <td>-0.965236</td>\n",
       "      <td>0.792749</td>\n",
       "      <td>-1.158343</td>\n",
       "      <td>-1.116147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.145073</td>\n",
       "      <td>2.200319</td>\n",
       "      <td>-1.237597</td>\n",
       "      <td>1.015114</td>\n",
       "      <td>-1.294232</td>\n",
       "      <td>0.162596</td>\n",
       "      <td>-1.098502</td>\n",
       "      <td>1.498673</td>\n",
       "      <td>1.316946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>-0.986076</td>\n",
       "      <td>-0.555247</td>\n",
       "      <td>-0.688773</td>\n",
       "      <td>1.015114</td>\n",
       "      <td>-1.294232</td>\n",
       "      <td>1.290428</td>\n",
       "      <td>1.423167</td>\n",
       "      <td>1.031207</td>\n",
       "      <td>0.561484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>-0.425407</td>\n",
       "      <td>0.546980</td>\n",
       "      <td>-0.688773</td>\n",
       "      <td>1.015114</td>\n",
       "      <td>1.459453</td>\n",
       "      <td>0.162596</td>\n",
       "      <td>-1.098502</td>\n",
       "      <td>1.707776</td>\n",
       "      <td>2.231730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>-1.827079</td>\n",
       "      <td>-0.555247</td>\n",
       "      <td>-1.512008</td>\n",
       "      <td>1.015114</td>\n",
       "      <td>0.541558</td>\n",
       "      <td>1.290428</td>\n",
       "      <td>0.792749</td>\n",
       "      <td>1.021154</td>\n",
       "      <td>1.010963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.695930</td>\n",
       "      <td>-0.555247</td>\n",
       "      <td>0.957697</td>\n",
       "      <td>-0.985111</td>\n",
       "      <td>-0.376337</td>\n",
       "      <td>0.162596</td>\n",
       "      <td>-1.098502</td>\n",
       "      <td>-0.917070</td>\n",
       "      <td>-0.922006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1.536933</td>\n",
       "      <td>1.098093</td>\n",
       "      <td>0.957697</td>\n",
       "      <td>-0.985111</td>\n",
       "      <td>-1.294232</td>\n",
       "      <td>0.162596</td>\n",
       "      <td>-0.468085</td>\n",
       "      <td>-0.775322</td>\n",
       "      <td>-0.954715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \n",
       "0   -0.986076 -0.555247 -0.688773  1.015114 -0.376337 -0.965236  0.162332  \\\n",
       "1   -1.266410 -0.004133 -1.237597  1.015114 -0.376337  0.162596 -0.468085   \n",
       "2    1.536933  1.098093  0.957697 -0.985111 -1.294232  0.162596  0.162332   \n",
       "3    0.415596 -1.106360  0.957697 -0.985111  0.541558 -0.965236  0.792749   \n",
       "4   -0.145073  2.200319 -1.237597  1.015114 -1.294232  0.162596 -1.098502   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "395 -0.986076 -0.555247 -0.688773  1.015114 -1.294232  1.290428  1.423167   \n",
       "396 -0.425407  0.546980 -0.688773  1.015114  1.459453  0.162596 -1.098502   \n",
       "397 -1.827079 -0.555247 -1.512008  1.015114  0.541558  1.290428  0.792749   \n",
       "398  0.695930 -0.555247  0.957697 -0.985111 -0.376337  0.162596 -1.098502   \n",
       "399  1.536933  1.098093  0.957697 -0.985111 -1.294232  0.162596 -0.468085   \n",
       "\n",
       "            7         8  \n",
       "0    0.444110  0.700759  \n",
       "1    1.127716  0.872743  \n",
       "2   -0.818550 -1.000084  \n",
       "3   -1.158343 -1.116147  \n",
       "4    1.498673  1.316946  \n",
       "..        ...       ...  \n",
       "395  1.031207  0.561484  \n",
       "396  1.707776  2.231730  \n",
       "397  1.021154  1.010963  \n",
       "398 -0.917070 -0.922006  \n",
       "399 -0.775322 -0.954715  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "#pd.DataFrame(X_train, columns=['Radio', 'Textura', 'Perímetro', 'Área', 'Suavidad', 'Compacidad', 'Concavidad', 'Puntos cóncavos', 'Simetría', 'Dimensión fractal'])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que los datos de entrada presentan magnitudes diferentes entre sí, vamos a necesitar estandarizarlos, para lo cual le restamos a cada instancia su media y dividimos por su desvío estándar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train.mean(axis=0)) / X_train.std(axis=0)\n",
    "X_test = (X_test - X_train.mean(axis=0)) / X_train.std(axis=0)\n",
    "X_val = (X_val - X_train.mean(axis=0)) / X_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = len(X)              # cantidad de instancias\n",
    "N = 10                  # unidades de entrada\n",
    "M = 1                   # unidades de salida\n",
    "S = [N, 20, 8, M]       # distribución de nodos por capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_CancerDeMamas:\n",
    "    def __init__(self, units_per_layers):\n",
    "        self.S = units_per_layers\n",
    "        self.L = len(self.S)\n",
    "        self.Y = self._initialize_Y \n",
    "        self.W = self._initialize_W  \n",
    "        self.dW = self._initialize_dW \n",
    "        self.lr = 1e-2\n",
    "\n",
    "    def activation(self, X):\n",
    "        activation = X\n",
    "\n",
    "        for k in range(1, self.L):\n",
    "            self.Y[k-1] = self._add_bias(activation)\n",
    "            activation = np.tanh(self.Y[k-1] @ self.W[k])\n",
    "        \n",
    "        self.Y[self.L - 1] = activation\n",
    "\n",
    "        return self.Y\n",
    "    \n",
    "    def correction(self, Z):\n",
    "        E = Z - self.Y[self.L - 1]\n",
    "        dY = 1 - np.square(self.Y[self.L - 1])\n",
    "        D = [None] * (self.L)\n",
    "        D[self.L-1] = E*dY\n",
    "\n",
    "        for k in range(self.L-1, 1, -1):\n",
    "            self.dW[k] = self.lr * (self.Y[k-1].T @ D[k])\n",
    "            E = D[k] @ self.W[k].T\n",
    "            dY = 1 - np.square(self.Y[k-1])\n",
    "            D[k-1] = self._sub_bias(E*dY)\n",
    "        return self.dW\n",
    "    \n",
    "    def adaptation(self):\n",
    "        return [ self.W[k] + self.dW[k] for k in range(self.L-1) ]\n",
    "    \n",
    "    def estimation(self, Z):\n",
    "        return np.sum(np.square(Z-self.Y))\n",
    "\n",
    "\n",
    "    def train(self, X, Z, epochs, batch_size):\n",
    "        t = 0\n",
    "        errores = []\n",
    "        while t < epochs:\n",
    "            e = 0\n",
    "            indices = np.random.permutation(len(X))\n",
    "            for batch in range(0, len(indices), batch_size):\n",
    "                h  = indices[batch : batch+batch_size]\n",
    "                Xh = X[h]\n",
    "                Zh = Z[h]\n",
    "                Yh = self.activation(Xh)\n",
    "                e += np.mean(np.square(np.subtract(Zh, np.sign(Yh[self.L-1].T))))\n",
    "                dW = self.correction(Zh)\n",
    "                W  = self.adaptation()\n",
    "            errores.append(e)\n",
    "            t += 1\n",
    "            if t % 100 == 0:\n",
    "                print(t, e)\n",
    "        plt.plot(errores, 'r')\n",
    "        plt.show()\n",
    "    \n",
    "        return self.W\n",
    "\n",
    "    ## Funciones privadas\n",
    "\n",
    "    def _bias_add(self, V):\n",
    "        bias = np.ones((len(V), 1))\n",
    "        return np.hstack([V, bias])\n",
    "\n",
    "    def _bias_sub(self, V):\n",
    "        return V[:,:-1]\n",
    "    \n",
    "    def _initialize_Y(self):\n",
    "        Y = []\n",
    "        for i in range(self.L):\n",
    "            if i == (self.L - 1):\n",
    "                Y.append(np.zeros(self.S[i]))\n",
    "            else:    \n",
    "                Y.append(np.zeros(self.S[i] + 1))\n",
    "        return Y\n",
    "\n",
    "    def _initialize_W(self):\n",
    "        W = []\n",
    "        W.append([])\n",
    "        W.append([np.random.normal(0, 1, (self.S[i-1] + 1, self.S[i])) for i in range(self.L)]) \n",
    "        return W\n",
    "\n",
    "    def _initialize_dW(self): \n",
    "        dW = []\n",
    "        dW.append([])\n",
    "        dW.append([np.random.normal(0, 1, (self.S[i-1] + 1, self.S[i])) for i in range(self.L)]) \n",
    "        return dW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eficiencia de energía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://git.exactas.uba.ar/redes-neuronales/clases/-/raw/master/practicas/datos/tp1_ej2_training.csv')\n",
    "data = np.loadtxt(r.iter_lines(), delimiter=',')\n",
    "\n",
    "data = np.random.RandomState(seed=42).permutation(data)\n",
    "\n",
    "X = data[:,1:]\n",
    "\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "Z = data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Z_train, X_val, Z_val, X_test, Z_test = split(X, Z, 0.05, 0.8, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = len(X)\n",
    "N = 10                  # unidades de entrada\n",
    "M = 1                   # unidades de salida\n",
    "S = [N, 20, 8, M]       # distribución de nodos por capa\n",
    "LR = 1e-3               # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_EficienciaDeEnergía:\n",
    "    def __init__(self, units_per_layers):\n",
    "        self.S = units_per_layers\n",
    "        self.L = len(self.S)\n",
    "        self.Y = self._initialize_Y \n",
    "        self.W = self._initialize_W  \n",
    "        self.dW = self._initialize_dW \n",
    "        self.lr = 1e-2\n",
    "\n",
    "    def activation(self, X):\n",
    "        activation = X\n",
    "\n",
    "        for k in range(1, self.L):\n",
    "            self.Y[k-1] = self._add_bias(activation)\n",
    "            activation = np.tanh(self.Y[k-1] @ self.W[k])\n",
    "        \n",
    "        self.Y[self.L - 1] = activation\n",
    "\n",
    "        return self.Y\n",
    "    \n",
    "    def correction(self, Z):\n",
    "        E = Z - self.Y[self.L - 1]\n",
    "        dY = 1 - np.square(self.Y[self.L - 1])\n",
    "        D = [None] * (self.L)\n",
    "        D[self.L-1] = E*dY\n",
    "\n",
    "        for k in range(self.L-1, 1, -1):\n",
    "            self.dW[k] = self.lr * (self.Y[k-1].T @ D[k])\n",
    "            E = D[k] @ self.W[k].T\n",
    "            dY = 1 - np.square(self.Y[k-1])\n",
    "            D[k-1] = self._sub_bias(E*dY)\n",
    "        return self.dW\n",
    "    \n",
    "    def adaptation(self):\n",
    "        return [ self.W[k] + self.dW[k] for k in range(self.L-1) ]\n",
    "    \n",
    "    def estimation(self, Z):\n",
    "        return np.sum(np.square(Z-self.Y))\n",
    "\n",
    "\n",
    "    def train(self, X, Z, epochs, batch_size):\n",
    "       \n",
    "        return self.W\n",
    "\n",
    "    ## Funciones privadas\n",
    "\n",
    "    def _bias_add(self, V):\n",
    "        bias = np.ones((len(V), 1))\n",
    "        return np.hstack([V, bias])\n",
    "\n",
    "    def _bias_sub(self, V):\n",
    "        return V[:,:-1]\n",
    "    \n",
    "    def _initialize_Y(self):\n",
    "        Y = []\n",
    "        for i in range(self.L):\n",
    "            if i == (self.L - 1):\n",
    "                Y.append(np.zeros(self.S[i]))\n",
    "            else:    \n",
    "                Y.append(np.zeros(self.S[i] + 1))\n",
    "        return Y\n",
    "\n",
    "    def _initialize_W(self):\n",
    "        W = []\n",
    "        W.append([])\n",
    "        W.append([np.random.normal(0, 1, (self.S[i-1] + 1, self.S[i])) for i in range(self.L)]) \n",
    "        return W\n",
    "\n",
    "    def _initialize_dW(self): \n",
    "        dW = []\n",
    "        dW.append([])\n",
    "        dW.append([np.random.normal(0, 1, (self.S[i-1] + 1, self.S[i])) for i in range(self.L)]) \n",
    "        return dW"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
