{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales Artificiales - Trabajo Práctico 1\n",
    "\n",
    "### Guillermina Cabrol, Magalí Giansiracusa, Sofía Goldberg\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En este trabajo implementaremos modelos de redes neuronales artificiales para aprendizaje supervisado, para dos problemas distintos: **Diagnóstico de cáncer de mamas** y **Eficiencia energética**. Se hará un análisis de los datos obtenidos y los modelos construidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt, cm\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una función para separar los datos en entrenamiento (`train`), validación (`val`) y testeo (`test`). Como sus nombres indican, usaremos los datos de entrenamiento para entrenar la red, los de validación para comprobar qué tan bien predice la red para datos no utilizados en el entrenamiento y poder ajustar parámetros para mejorar la performance, y por último, usaremos el dataset de testeo para calificar el modelo final y estimar su desempeño en la realidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, floor\n",
    "import random\n",
    "\n",
    "def split(\n",
    "        X: np.ndarray,\n",
    "        Z: np.ndarray,\n",
    "        test_size: float,\n",
    "        train_size: int,\n",
    "        val_size: int,\n",
    "    ) -> tuple:\n",
    "\n",
    "    \"\"\"Separa el conjunto de datos en conjuntos de train, validation y test al azar.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: datos de entrada.\n",
    "    \n",
    "    Z: datos objetivo.\n",
    "\n",
    "    test_size: proporción del dataset a incluir en test.\n",
    "    \n",
    "    train_size: proporción del dataset a incluir en train.\n",
    "\n",
    "    val_size: proporción del dataset a incluir en validation.\n",
    "\n",
    "    random_state: sirve para que los resultados sean reproducibles.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    split: lista que contiene el conjunto de test y el de train.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(X)\n",
    "\n",
    "    n_test = ceil(test_size * n)\n",
    "    n_train = floor(train_size * n)\n",
    "    n_val = ceil(val_size * n)\n",
    "\n",
    "    n_train, n_test, n_val = int(n_train), int(n_test), int(n_val)\n",
    "\n",
    "\n",
    "    X_train = X[:n_train]\n",
    "    X_test = X[(n_train + 1):(n_train + n_test + 1)]\n",
    "    X_val = X[(n_train + n_test):(n_train + n_test + n_val)]\n",
    "\n",
    "    Z_train = Z[:n_train]\n",
    "    Z_test = Z[(n_train + 1):(n_train + n_test + 1)]\n",
    "    Z_val = Z[(n_train + n_test):(n_train + n_test + n_val)]\n",
    "\n",
    "    return X_train, Z_train, X_val, Z_val, X_test, Z_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnóstico de cáncer de mamas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, cargamos los datos, y los separamos en X (datos de entrada) y Z (datos objetivo).\n",
    "\n",
    "Ya que los datos de entrada presentan magnitudes diferentes entre sí, vamos a necesitar estandarizarlos, para lo cual le restamos a cada instancia su media y dividimos por su desvío estándar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://git.exactas.uba.ar/redes-neuronales/clases/-/raw/master/practicas/datos/tp1_ej1_training.csv')\n",
    "data = np.loadtxt(r.iter_lines(), delimiter=',')\n",
    "\n",
    "data = np.random.RandomState(seed=42).permutation(data)\n",
    "\n",
    "X = data[:,1:]\n",
    "\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "Z = data[:,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos:\n",
    "\n",
    "- 80% para entrenamiento.\n",
    "- 15% para validación.\n",
    "- 5% para testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Z_train, X_val, Z_val, X_test, Z_test = split(X, Z, 0.05, 0.8, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = len(X)              # cantidad de instancias\n",
    "N = 10                  # unidades de entrada\n",
    "M = 1                   # unidades de salida\n",
    "S = [N, 20, 8, M]       # distribución de nodos por capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_CancerDeMamas:\n",
    "    def __init__(self, units_per_layers):\n",
    "        self.S = units_per_layers\n",
    "        self.L = len(self.S)\n",
    "        self.Y = self._initialize_Y \n",
    "        self.W = self._initialize_W  \n",
    "        self.dW = self._initialize_dW \n",
    "        self.lr = 1e-2\n",
    "\n",
    "    def activation(self, X):\n",
    "        activation = X\n",
    "\n",
    "        for k in range(1, self.L):\n",
    "            self.Y[k-1] = self._add_bias(activation)\n",
    "            activation = np.tanh(self.Y[k-1] @ self.W[k])\n",
    "        \n",
    "        self.Y[self.L - 1] = activation\n",
    "\n",
    "        return self.Y\n",
    "    \n",
    "    def correction(self, Z):\n",
    "        E = Z - self.Y[self.L - 1]\n",
    "        dY = 1 - np.square(self.Y[self.L - 1])\n",
    "        D = [None] * (self.L)\n",
    "        D[self.L-1] = E*dY\n",
    "\n",
    "        for k in range(self.L-1, 1, -1):\n",
    "            self.dW[k] = self.lr * (self.Y[k-1].T @ D[k])\n",
    "            E = D[k] @ self.W[k].T\n",
    "            dY = 1 - np.square(self.Y[k-1])\n",
    "            D[k-1] = self._sub_bias(E*dY)\n",
    "        return self.dW\n",
    "    \n",
    "    def adaptation(self):\n",
    "        return [ self.W[k] + self.dW[k] for k in range(self.L-1) ]\n",
    "    \n",
    "    def estimation(self, Z):\n",
    "        return np.sum(np.square(Z-self.Y))\n",
    "\n",
    "\n",
    "    def train(self, X, Z, epochs, batch_size):\n",
    "        t = 0\n",
    "        errores = []\n",
    "        while t < epochs:\n",
    "            e = 0\n",
    "            indices = np.random.permutation(len(X))\n",
    "            for batch in range(0, len(indices), batch_size):\n",
    "                h  = indices[batch : batch+batch_size]\n",
    "                Xh = X[h]\n",
    "                Zh = Z[h]\n",
    "                Yh = self.activation(Xh)\n",
    "                e += np.mean(np.square(np.subtract(Zh, np.sign(Yh[self.L-1].T))))\n",
    "                dW = self.correction(Zh)\n",
    "                W  = self.adaptation()\n",
    "            errores.append(e)\n",
    "            t += 1\n",
    "            if t % 100 == 0:\n",
    "                print(t, e)\n",
    "        plt.plot(errores, 'r')\n",
    "        plt.show()\n",
    "    \n",
    "        return self.W\n",
    "\n",
    "    ## Funciones privadas\n",
    "\n",
    "    def _bias_add(self, V):\n",
    "        bias = np.ones((len(V), 1))\n",
    "        return np.hstack([V, bias])\n",
    "\n",
    "    def _bias_sub(self, V):\n",
    "        return V[:,:-1]\n",
    "    \n",
    "    def _initialize_Y(self):\n",
    "        Y = []\n",
    "        for i in range(self.L):\n",
    "            if i == (self.L - 1):\n",
    "                Y.append(np.zeros(self.S[i]))\n",
    "            else:    \n",
    "                Y.append(np.zeros(self.S[i] + 1))\n",
    "        return Y\n",
    "\n",
    "    def _initialize_W(self):\n",
    "        W = []\n",
    "        W.append([])\n",
    "        W.append([np.random.normal(0, 1, (self.S[i-1] + 1, self.S[i])) for i in range(self.L)]) \n",
    "        return W\n",
    "\n",
    "    def _initialize_dW(self): \n",
    "        dW = []\n",
    "        dW.append([])\n",
    "        dW.append([np.random.normal(0, 1, (self.S[i-1] + 1, self.S[i])) for i in range(self.L)]) \n",
    "        return dW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eficiencia de energía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://git.exactas.uba.ar/redes-neuronales/clases/-/raw/master/practicas/datos/tp1_ej2_training.csv')\n",
    "data = np.loadtxt(r.iter_lines(), delimiter=',')\n",
    "\n",
    "data = np.random.RandomState(seed=42).permutation(data)\n",
    "\n",
    "X = data[:,1:]\n",
    "\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "Z = data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Z_train, X_val, Z_val, X_test, Z_test = split(X, Z, 0.05, 0.8, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = len(X)\n",
    "N = 10                  # unidades de entrada\n",
    "M = 1                   # unidades de salida\n",
    "S = [N, 20, 8, M]       # distribución de nodos por capa\n",
    "LR = 1e-3               # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_EficienciaDeEnergía:\n",
    "    def __init__(self, units_per_layers):\n",
    "        self.S = units_per_layers\n",
    "        self.L = len(self.S)\n",
    "        self.Y = self._initialize_Y \n",
    "        self.W = self._initialize_W  \n",
    "        self.dW = self._initialize_dW \n",
    "        self.lr = 1e-2\n",
    "\n",
    "    def activation(self, X):\n",
    "        activation = X\n",
    "\n",
    "        for k in range(1, self.L):\n",
    "            self.Y[k-1] = self._add_bias(activation)\n",
    "            activation = np.tanh(self.Y[k-1] @ self.W[k])\n",
    "        \n",
    "        self.Y[self.L - 1] = activation\n",
    "\n",
    "        return self.Y\n",
    "    \n",
    "    def correction(self, Z):\n",
    "        E = Z - self.Y[self.L - 1]\n",
    "        dY = 1 - np.square(self.Y[self.L - 1])\n",
    "        D = [None] * (self.L)\n",
    "        D[self.L-1] = E*dY\n",
    "\n",
    "        for k in range(self.L-1, 1, -1):\n",
    "            self.dW[k] = self.lr * (self.Y[k-1].T @ D[k])\n",
    "            E = D[k] @ self.W[k].T\n",
    "            dY = 1 - np.square(self.Y[k-1])\n",
    "            D[k-1] = self._sub_bias(E*dY)\n",
    "        return self.dW\n",
    "    \n",
    "    def adaptation(self):\n",
    "        return [ self.W[k] + self.dW[k] for k in range(self.L-1) ]\n",
    "    \n",
    "    def estimation(self, Z):\n",
    "        return np.sum(np.square(Z-self.Y))\n",
    "\n",
    "\n",
    "    def train(self, X, Z, epochs, batch_size):\n",
    "       \n",
    "        return self.W\n",
    "\n",
    "    ## Funciones privadas\n",
    "\n",
    "    def _bias_add(self, V):\n",
    "        bias = np.ones((len(V), 1))\n",
    "        return np.hstack([V, bias])\n",
    "\n",
    "    def _bias_sub(self, V):\n",
    "        return V[:,:-1]\n",
    "    \n",
    "    def _initialize_Y(self):\n",
    "        Y = []\n",
    "        for i in range(self.L):\n",
    "            if i == (self.L - 1):\n",
    "                Y.append(np.zeros(self.S[i]))\n",
    "            else:    \n",
    "                Y.append(np.zeros(self.S[i] + 1))\n",
    "        return Y\n",
    "\n",
    "    def _initialize_W(self):\n",
    "        W = []\n",
    "        W.append([])\n",
    "        W.append([np.random.normal(0, 1, (self.S[i-1] + 1, self.S[i])) for i in range(self.L)]) \n",
    "        return W\n",
    "\n",
    "    def _initialize_dW(self): \n",
    "        dW = []\n",
    "        dW.append([])\n",
    "        dW.append([np.random.normal(0, 1, (self.S[i-1] + 1, self.S[i])) for i in range(self.L)]) \n",
    "        return dW"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
