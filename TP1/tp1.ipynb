{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales Artificiales - Trabajo Práctico 1\n",
    "\n",
    "### Guillermina Cabrol, Magalí Giansiracusa, Sofía Goldberg\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En este trabajo implementaremos modelos de redes neuronales artificiales para aprendizaje supervisado, para dos problemas distintos: **Diagnóstico de cáncer de mamas** y **Eficiencia energética**. Se hará un análisis de los datos obtenidos y los modelos construidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt, cm\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una función para separar los datos en entrenamiento (`train`), validación (`val`) y testeo (`test`). Como sus nombres indican, usaremos los datos de entrenamiento para entrenar la red, los de validación para comprobar qué tan bien predice la red para datos no utilizados en el entrenamiento y poder ajustar parámetros para mejorar la performance, y por último, usaremos el dataset de testeo para calificar el modelo final y estimar su desempeño en la realidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, floor\n",
    "import random\n",
    "\n",
    "def split(\n",
    "        X: np.ndarray,\n",
    "        Z: np.ndarray,\n",
    "        test_size: float,\n",
    "        train_size: int,\n",
    "        val_size: int,\n",
    "    ) -> tuple:\n",
    "\n",
    "    \"\"\"Separa el conjunto de datos en conjuntos de train, validation y test al azar.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: datos de entrada.\n",
    "    \n",
    "    Z: datos objetivo.\n",
    "\n",
    "    test_size: proporción del dataset a incluir en test.\n",
    "    \n",
    "    train_size: proporción del dataset a incluir en train.\n",
    "\n",
    "    val_size: proporción del dataset a incluir en validation.\n",
    "\n",
    "    random_state: sirve para que los resultados sean reproducibles.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    split: lista que contiene el conjunto de test y el de train.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(X)\n",
    "\n",
    "    n_test = ceil(test_size * n)\n",
    "    n_train = floor(train_size * n)\n",
    "    n_val = ceil(val_size * n)\n",
    "\n",
    "    n_train, n_test, n_val = int(n_train), int(n_test), int(n_val)\n",
    "\n",
    "\n",
    "    X_train = X[:n_train]\n",
    "    X_test = X[(n_train ):(n_train + n_test)]\n",
    "    X_val = X[(n_train + n_test):(n_train + n_test + n_val)]\n",
    "\n",
    "    Z_train = Z[:n_train]\n",
    "    Z_test = Z[(n_train ):(n_train + n_test)]\n",
    "    Z_val = Z[(n_train + n_test):(n_train + n_test + n_val)]\n",
    "\n",
    "    return X_train, Z_train, X_val, Z_val, X_test, Z_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnóstico de cáncer de mamas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, cargamos los datos, y los separamos en X (datos de entrada) y Z (datos objetivo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "r = requests.get('https://git.exactas.uba.ar/redes-neuronales/clases/-/raw/master/practicas/datos/tp1_ej1_training.csv')\n",
    "data = np.loadtxt(r.iter_lines(), delimiter=',')\n",
    "\n",
    "\n",
    "\n",
    "data = np.random.RandomState(seed=42).permutation(data)\n",
    "\n",
    "X = data[:,1:]\n",
    "\n",
    "Z = data[:,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos:\n",
    "\n",
    "- 80% para entrenamiento.\n",
    "- 15% para validación.\n",
    "- 5% para testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Z_train, X_val, Z_val, X_test, Z_test = split(X, Z, 0.05, 0.8, 0.15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de datos\n",
    "\n",
    "Vamos a realizar un análisis de los datos para ver su distribución y cuán correlacionados están, para así decidir si es necesario realizar alguna modificación.\n",
    "\n",
    "Para esto, pasaremos los datos a formato *DataFrame* usando la librería `Pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Radio</th>\n",
       "      <th>Textura</th>\n",
       "      <th>Perímetro</th>\n",
       "      <th>Área</th>\n",
       "      <th>Suavidad</th>\n",
       "      <th>Compacidad</th>\n",
       "      <th>Concavidad</th>\n",
       "      <th>Puntos cóncavos</th>\n",
       "      <th>Simetría</th>\n",
       "      <th>Dimensión fractal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.284</td>\n",
       "      <td>13.181</td>\n",
       "      <td>158.656</td>\n",
       "      <td>1179.240</td>\n",
       "      <td>1.205</td>\n",
       "      <td>1.878</td>\n",
       "      <td>4.898</td>\n",
       "      <td>5.932</td>\n",
       "      <td>1.029</td>\n",
       "      <td>2.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.298</td>\n",
       "      <td>11.596</td>\n",
       "      <td>154.492</td>\n",
       "      <td>1370.281</td>\n",
       "      <td>0.933</td>\n",
       "      <td>1.291</td>\n",
       "      <td>5.229</td>\n",
       "      <td>6.866</td>\n",
       "      <td>0.760</td>\n",
       "      <td>2.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.810</td>\n",
       "      <td>26.490</td>\n",
       "      <td>48.872</td>\n",
       "      <td>740.533</td>\n",
       "      <td>1.970</td>\n",
       "      <td>2.042</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.137</td>\n",
       "      <td>15.136</td>\n",
       "      <td>94.484</td>\n",
       "      <td>694.296</td>\n",
       "      <td>1.594</td>\n",
       "      <td>0.683</td>\n",
       "      <td>1.846</td>\n",
       "      <td>2.414</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.586</td>\n",
       "      <td>12.223</td>\n",
       "      <td>147.360</td>\n",
       "      <td>1598.108</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.121</td>\n",
       "      <td>3.131</td>\n",
       "      <td>2.793</td>\n",
       "      <td>0.814</td>\n",
       "      <td>1.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>25.037</td>\n",
       "      <td>18.467</td>\n",
       "      <td>78.939</td>\n",
       "      <td>371.967</td>\n",
       "      <td>1.770</td>\n",
       "      <td>1.504</td>\n",
       "      <td>1.338</td>\n",
       "      <td>1.802</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>20.723</td>\n",
       "      <td>26.535</td>\n",
       "      <td>90.812</td>\n",
       "      <td>742.614</td>\n",
       "      <td>1.972</td>\n",
       "      <td>1.682</td>\n",
       "      <td>2.265</td>\n",
       "      <td>2.119</td>\n",
       "      <td>0.843</td>\n",
       "      <td>1.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>18.179</td>\n",
       "      <td>13.237</td>\n",
       "      <td>152.105</td>\n",
       "      <td>1134.127</td>\n",
       "      <td>1.239</td>\n",
       "      <td>1.893</td>\n",
       "      <td>5.015</td>\n",
       "      <td>6.325</td>\n",
       "      <td>0.572</td>\n",
       "      <td>2.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>17.415</td>\n",
       "      <td>22.883</td>\n",
       "      <td>83.133</td>\n",
       "      <td>366.730</td>\n",
       "      <td>1.783</td>\n",
       "      <td>2.640</td>\n",
       "      <td>2.928</td>\n",
       "      <td>4.197</td>\n",
       "      <td>0.394</td>\n",
       "      <td>1.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>16.014</td>\n",
       "      <td>28.302</td>\n",
       "      <td>85.181</td>\n",
       "      <td>969.770</td>\n",
       "      <td>2.177</td>\n",
       "      <td>1.208</td>\n",
       "      <td>3.646</td>\n",
       "      <td>5.480</td>\n",
       "      <td>1.217</td>\n",
       "      <td>0.593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Radio  Textura  Perímetro      Área  Suavidad  Compacidad  Concavidad  \\\n",
       "0    20.284   13.181    158.656  1179.240     1.205       1.878       4.898   \n",
       "1    18.298   11.596    154.492  1370.281     0.933       1.291       5.229   \n",
       "2    23.810   26.490     48.872   740.533     1.970       2.042       0.427   \n",
       "3    25.137   15.136     94.484   694.296     1.594       0.683       1.846   \n",
       "4    25.586   12.223    147.360  1598.108     0.816       1.121       3.131   \n",
       "..      ...      ...        ...       ...       ...         ...         ...   \n",
       "323  25.037   18.467     78.939   371.967     1.770       1.504       1.338   \n",
       "324  20.723   26.535     90.812   742.614     1.972       1.682       2.265   \n",
       "325  18.179   13.237    152.105  1134.127     1.239       1.893       5.015   \n",
       "326  17.415   22.883     83.133   366.730     1.783       2.640       2.928   \n",
       "327  16.014   28.302     85.181   969.770     2.177       1.208       3.646   \n",
       "\n",
       "     Puntos cóncavos  Simetría  Dimensión fractal  \n",
       "0              5.932     1.029              2.019  \n",
       "1              6.866     0.760              2.164  \n",
       "2              0.434     0.651              0.267  \n",
       "3              2.414     0.784              0.830  \n",
       "4              2.793     0.814              1.933  \n",
       "..               ...       ...                ...  \n",
       "323            1.802     0.768              0.579  \n",
       "324            2.119     0.843              1.098  \n",
       "325            6.325     0.572              2.340  \n",
       "326            4.197     0.394              1.249  \n",
       "327            5.480     1.217              0.593  \n",
       "\n",
       "[328 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.DataFrame(X_train, columns=['Radio', 'Textura', 'Perímetro', 'Área', 'Suavidad', 'Compacidad', 'Concavidad', 'Puntos cóncavos', 'Simetría', 'Dimensión fractal'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que los datos de entrada presentan magnitudes diferentes entre sí, vamos a necesitar estandarizarlos, para lo cual le restamos a cada instancia su media y dividimos por su desvío estándar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train.mean(axis=0)) / X_train.std(axis=0)\n",
    "X_test = (X_test - X_train.mean(axis=0)) / X_train.std(axis=0)\n",
    "X_val = (X_val - X_train.mean(axis=0)) / X_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = X.shape[0]             # cantidad de instancias\n",
    "N = 10                  # unidades de entrada\n",
    "M = 1                   # unidades de salida\n",
    "S = [N, 20, 8, M]       # distribución de nodos por capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_CancerDeMamas:\n",
    "    def __init__(self, units_per_layers):\n",
    "        self.S = units_per_layers\n",
    "        self.L = len(self.S)\n",
    "        self.Y = self._initialize_Y() \n",
    "        self.W = self._initialize_W()  \n",
    "        self.dW = self._initialize_dW() \n",
    "        self.lr = 1e-2\n",
    "\n",
    "    def activation(self, X):\n",
    "        activation = X\n",
    "\n",
    "        for k in range(1, self.L):\n",
    "            self.Y[k-1] = self._add_bias(activation)\n",
    "            activation = np.tanh(self.Y[k-1] @ self.W[k])\n",
    "        \n",
    "        self.Y[self.L - 1] = activation\n",
    "\n",
    "        return self.Y\n",
    "    \n",
    "    def correction(self, Z):\n",
    "        E = Z - self.Y[self.L - 1]\n",
    "        dY = 1 - np.square(self.Y[self.L - 1])\n",
    "        D = [None] * (self.L)\n",
    "        D[self.L-1] = E*dY\n",
    "\n",
    "        for k in range(self.L-1, 1, -1):\n",
    "            self.dW[k] = self.lr * (self.Y[k-1].T @ D[k])\n",
    "            E = D[k] @ self.W[k].T\n",
    "            dY = 1 - np.square(self.Y[k-1])\n",
    "            D[k-1] = self._sub_bias(E*dY)\n",
    "        return self.dW\n",
    "    \n",
    "    def adaptation(self):\n",
    "        return [ self.W[k] + self.dW[k] for k in range(self.L-1) ]\n",
    "    \n",
    "    def estimation(self, Z):\n",
    "        return np.sum(np.square(Z-self.Y))\n",
    "\n",
    "\n",
    "    def train(self, X, Z, epochs, batch_size):\n",
    "        t = 0\n",
    "        errores = []\n",
    "        while t < epochs:\n",
    "            e = 0\n",
    "            indices = np.random.permutation(len(X))\n",
    "            for batch in range(0, len(indices), batch_size):\n",
    "                h  = indices[batch : batch+batch_size]\n",
    "                Xh = X[h]\n",
    "                Zh = Z[h]\n",
    "                Yh = self.activation(Xh)\n",
    "                e += np.mean(np.square(np.subtract(Zh, np.sign(Yh[self.L-1].T))))\n",
    "                dW = self.correction(Zh)\n",
    "                W  = self.adaptation()\n",
    "            errores.append(e)\n",
    "            t += 1\n",
    "            if t % 100 == 0:\n",
    "                print(t, e)\n",
    "        plt.plot(errores, 'r')\n",
    "        plt.show()\n",
    "    \n",
    "        return self.W\n",
    "\n",
    "    ## Funciones privadas\n",
    "\n",
    "    def _bias_add(self, V):\n",
    "        bias = np.ones((len(V), 1))\n",
    "        return np.hstack([V, bias])\n",
    "\n",
    "    def _bias_sub(self, V):\n",
    "        return V[:,:-1]\n",
    "    \n",
    "    def _initialize_Y(self):\n",
    "        Y = []\n",
    "        for i in range(self.L):\n",
    "            if i == (self.L - 1):\n",
    "                Y.append(np.zeros(self.S[i]))\n",
    "            else:    \n",
    "                Y.append(np.zeros(self.S[i] + 1))\n",
    "        return Y\n",
    "\n",
    "    def _initialize_W(self):\n",
    "        W = []\n",
    "        W.append([])\n",
    "        W.append([np.random.normal(0, 1, (self.S[i-1] + 1, self.S[i])) for i in range(self.L)]) \n",
    "        return W\n",
    "\n",
    "    def _initialize_dW(self): \n",
    "        dW = []\n",
    "        dW.append([])\n",
    "        dW.append([np.random.normal(0, 1, (self.S[i-1] + 1, self.S[i])) for i in range(self.L)]) \n",
    "        return dW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eficiencia de energía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://git.exactas.uba.ar/redes-neuronales/clases/-/raw/master/practicas/datos/tp1_ej2_training.csv')\n",
    "data = np.loadtxt(r.iter_lines(), delimiter=',')\n",
    "\n",
    "data = np.random.RandomState(seed=42).permutation(data)\n",
    "\n",
    "X = data[:,1:]\n",
    "\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "Z = data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Z_train, X_val, Z_val, X_test, Z_test = split(X, Z, 0.05, 0.8, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = len(X)\n",
    "N = 10                  # unidades de entrada\n",
    "M = 1                   # unidades de salida\n",
    "S = [N, 20, 8, M]       # distribución de nodos por capa\n",
    "LR = 1e-3               # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_EficienciaDeEnergía:\n",
    "    def __init__(self, units_per_layers):\n",
    "        self.S = units_per_layers\n",
    "        self.L = len(self.S)\n",
    "        self.Y = self._initialize_Y \n",
    "        self.W = self._initialize_W  \n",
    "        self.dW = self._initialize_dW \n",
    "        self.lr = 1e-2\n",
    "\n",
    "    def activation(self, X):\n",
    "        activation = X\n",
    "\n",
    "        for k in range(1, self.L):\n",
    "            self.Y[k-1] = self._add_bias(activation)\n",
    "            activation = np.tanh(self.Y[k-1] @ self.W[k])\n",
    "        \n",
    "        self.Y[self.L - 1] = activation\n",
    "\n",
    "        return self.Y\n",
    "    \n",
    "    def correction(self, Z):\n",
    "        E = Z - self.Y[self.L - 1]\n",
    "        dY = 1 - np.square(self.Y[self.L - 1])\n",
    "        D = [None] * (self.L)\n",
    "        D[self.L-1] = E*dY\n",
    "\n",
    "        for k in range(self.L-1, 1, -1):\n",
    "            self.dW[k] = self.lr * (self.Y[k-1].T @ D[k])\n",
    "            E = D[k] @ self.W[k].T\n",
    "            dY = 1 - np.square(self.Y[k-1])\n",
    "            D[k-1] = self._sub_bias(E*dY)\n",
    "        return self.dW\n",
    "    \n",
    "    def adaptation(self):\n",
    "        return [ self.W[k] + self.dW[k] for k in range(self.L-1) ]\n",
    "    \n",
    "    def estimation(self, Z):\n",
    "        return np.sum(np.square(Z-self.Y))\n",
    "\n",
    "\n",
    "    def train(self, X, Z, epochs, batch_size):\n",
    "       \n",
    "        return self.W\n",
    "\n",
    "    ## Funciones privadas\n",
    "\n",
    "    def _bias_add(self, V):\n",
    "        bias = np.ones((len(V), 1))\n",
    "        return np.hstack([V, bias])\n",
    "\n",
    "    def _bias_sub(self, V):\n",
    "        return V[:,:-1]\n",
    "    \n",
    "    def _initialize_Y(self):\n",
    "        Y = []\n",
    "        for i in range(self.L):\n",
    "            if i == (self.L - 1):\n",
    "                Y.append(np.zeros(self.S[i]))\n",
    "            else:    \n",
    "                Y.append(np.zeros(self.S[i] + 1))\n",
    "        return Y\n",
    "\n",
    "    def _initialize_W(self):\n",
    "        W = []\n",
    "        W.append([])\n",
    "        W.append([np.random.normal(0, 1, (self.S[i-1] + 1, self.S[i])) for i in range(self.L)]) \n",
    "        return W\n",
    "\n",
    "    def _initialize_dW(self): \n",
    "        dW = []\n",
    "        dW.append([])\n",
    "        dW.append([np.random.normal(0, 1, (self.S[i-1] + 1, self.S[i])) for i in range(self.L)]) \n",
    "        return dW"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
