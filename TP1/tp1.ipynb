{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales Artificiales - Trabajo Práctico 1\n",
    "\n",
    "### Guillermina Cabrol, Magalí Giansiracusa, Sofía Goldberg\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En este trabajo implementaremos modelos de redes neuronales artificiales para aprendizaje supervisado, para dos problemas distintos. Se hará un análisis de los datos obtenidos y los modelos construidos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt, cm\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnóstico de cáncer de mamas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, cargamos los datos, separamos en X (datos de entrada) y Z (datos objetivo).\n",
    "\n",
    "Ya que los datos de entrada presentan magnitudes diferentes entre sí, vamos a necesitar estandarizarlos, para lo cual le restamos a cada instancia su media y dividimos por su desvío estándar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://git.exactas.uba.ar/redes-neuronales/clases/-/raw/master/practicas/datos/tp1_ej1_training.csv')\n",
    "data = np.loadtxt(r.iter_lines(), delimiter=',')\n",
    "\n",
    "data = np.random.RandomState(seed=42).permutation(data)\n",
    "\n",
    "X = data[:,1:]\n",
    "\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "Z = data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, floor\n",
    "import random\n",
    "\n",
    "def split(\n",
    "        X: np.ndarray,\n",
    "        Z: np.ndarray,\n",
    "        test_size: float,\n",
    "        train_size: int,\n",
    "        val_size: int,\n",
    "    ) -> tuple:\n",
    "\n",
    "    \"\"\"Separa el conjunto de datos en conjuntos de train, validation y test al azar.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: datos de entrada.\n",
    "    \n",
    "    Z: datos objetivo.\n",
    "\n",
    "    test_size: proporción del dataset a incluir en test.\n",
    "    \n",
    "    train_size: proporción del dataset a incluir en train.\n",
    "\n",
    "    val_size: proporción del dataset a incluir en validation.\n",
    "\n",
    "    random_state: sirve para que los resultados sean reproducibles.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    split: lista que contiene el conjunto de test y el de train.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(X)\n",
    "\n",
    "    n_test = ceil(test_size * n)\n",
    "    n_train = floor(train_size * n)\n",
    "    n_val = ceil(val_size * n)\n",
    "\n",
    "    n_train, n_test, n_val = int(n_train), int(n_test), int(n_val)\n",
    "\n",
    "\n",
    "    X_train = X[:n_train]\n",
    "    X_test = X[(n_train + 1):(n_train + n_test + 1)]\n",
    "    X_val = X[(n_train + n_test):(n_train + n_test + n_val)]\n",
    "\n",
    "    Z_train = Z[:n_train]\n",
    "    Z_test = Z[(n_train + 1):(n_train + n_test + 1)]\n",
    "    Z_val = Z[(n_train + n_test):(n_train + n_test + n_val)]\n",
    "\n",
    "    return X_train, Z_train, X_val, Z_val, X_test, Z_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Z_train, X_val, Z_val, X_test, Z_test = split(X, Z, 0.05, 0.8, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = len(X)\n",
    "N = 10                  # unidades de entrada\n",
    "M = 1                   # unidades de salida\n",
    "S = [N, 20, 8, M]       # distribución de nodos por capa\n",
    "L = len(S)              # cantidad de capas\n",
    "LR = 1e-3               # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP: # TODO: cambiar nombre\n",
    "    def __init__(self, layers):\n",
    "        self.S = layers\n",
    "        self.L = len(self.S)\n",
    "        self.Y = self._initialize_Y \n",
    "        self.W = self._initialize_W  \n",
    "        self.dW = self._initialize_dW \n",
    "        self.lr = 1e-2\n",
    "        self.error = 0.01\n",
    "        self.epoch = 1000\n",
    "\n",
    "    def activation(self, X):\n",
    "        activation = X\n",
    "\n",
    "        for k in range(1, self.L):\n",
    "            self.Y[k-1] = self._add_bias(activation)\n",
    "            activation = np.tanh(self.Y[k-1] @ self.W[k])\n",
    "        \n",
    "        self.Y[self.L - 1] = activation\n",
    "\n",
    "        return self.Y\n",
    "    \n",
    "    def correction(self, Z):\n",
    "        E = Z - self.Y[self.L - 1]\n",
    "        dY = 1 - np.square(self.Y[self.L - 1])\n",
    "        D = [None] * (self.L)\n",
    "        D[L-1] = E*dY\n",
    "\n",
    "        for k in range(L-1, 1, -1):\n",
    "            self.dW[k] = self.lr * (self.Y[k-1].T @ D[k])\n",
    "            E = D[k] @ self.W[k].T\n",
    "            dY = 1 - np.square(self.Y[k-1])\n",
    "            D[k-1] = self._sub_bias(E*dY)\n",
    "        return self.dW\n",
    "    \n",
    "    def adaptation(self):\n",
    "        return [ self.W[k] + self.dW[k] for k in range(L-1) ]\n",
    "    \n",
    "    def estimation(self, Z):\n",
    "        return np.sum(np.square(Z-self.Y))\n",
    "\n",
    "\n",
    "    def train(self, X, Z):\n",
    "        t = 0\n",
    "        while t < self.epochs:\n",
    "            self.activation(X)\n",
    "            self.correction(Z)\n",
    "            self.adaptation()\n",
    "\n",
    "    ## Funciones privadas\n",
    "\n",
    "    def _bias_add(self, V):\n",
    "        bias = np.ones((len(V), 1))\n",
    "        return np.hstack([V, bias])\n",
    "\n",
    "    def _bias_sub(self, V):\n",
    "        return V[:,:-1]\n",
    "    \n",
    "    def _initialize_Y(self):\n",
    "        Y = []\n",
    "        for i in range(self.L):\n",
    "            if i == (self.L - 1):\n",
    "                Y.append(np.zeros(self.S[i]+1))\n",
    "            else:    \n",
    "                Y.append(np.zeros(self.S[i] + 1))\n",
    "        return Y\n",
    "\n",
    "    def _initialize_W(self): # No se si está bien\n",
    "        W = [ np.random.randn(self.S[i]+1, self.S[i+1]) * np.sqrt(2/self.S[i]) for i in range(L-1) ]\n",
    "        return W\n",
    "\n",
    "    def _initialize_dW(self): # No se si está bien\n",
    "        dW = [ np.random.randn(self.S[i]+1, self.S[i+1]) * np.sqrt(2/self.S[i]) for i in range(L-1) ]\n",
    "        return dW\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
